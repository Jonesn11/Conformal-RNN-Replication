{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "038e8330",
   "metadata": {},
   "source": [
    "## Implementation of Conformal RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "410711a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import typing\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "914a005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "means = np.random.choice(range(0,100,1),size=2000)\n",
    "sdv = np.random.choice(range(0,100,1),size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random(0,5)\n",
    "ys = np.random.normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8cb19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryForecaster(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The auxiliary RNN issuing point predictions.\n",
    "    Point predictions are used as baseline to which the (normalised)\n",
    "    uncertainty intervals are added in the main CFRNN network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_size, input_size=1, output_size=1, horizon=1, rnn_mode=\"LSTM\", path=None):\n",
    "        \"\"\"\n",
    "        Initialises the auxiliary forecaster.\n",
    "        Args:\n",
    "            embedding_size: hyperparameter indicating the size of the latent\n",
    "                RNN embeddings.\n",
    "            input_size: dimensionality of the input time-series\n",
    "            output_size: dimensionality of the forecast\n",
    "            horizon: forecasting horizon\n",
    "            rnn_mode: type of the underlying RNN network\n",
    "            path: optional path where to save the auxiliary model to be used\n",
    "                in the main CFRNN network\n",
    "        \"\"\"\n",
    "        super(AuxiliaryForecaster, self).__init__()\n",
    "        # input_size indicates the number of features in the time series\n",
    "        # input_size=1 for univariate series.\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.horizon = horizon\n",
    "        self.output_size = output_size\n",
    "        self.path = path\n",
    "\n",
    "        self.rnn_mode = rnn_mode\n",
    "        if self.rnn_mode == \"RNN\":\n",
    "            self.forecaster_rnn = torch.nn.RNN(input_size=input_size, hidden_size=embedding_size, batch_first=True)\n",
    "        elif self.rnn_mode == \"GRU\":\n",
    "            self.forecaster_rnn = torch.nn.GRU(input_size=input_size, hidden_size=embedding_size, batch_first=True)\n",
    "        else:  # self.mode == 'LSTM'\n",
    "            self.forecaster_rnn = torch.nn.LSTM(input_size=input_size, hidden_size=embedding_size, batch_first=True)\n",
    "        self.forecaster_out = torch.nn.Linear(embedding_size, horizon * output_size)\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        if state is not None:\n",
    "            h_0, c_0 = state\n",
    "        else:\n",
    "            h_0 = None\n",
    "\n",
    "        # [batch, horizon, output_size]\n",
    "        if self.rnn_mode == \"LSTM\":\n",
    "            _, (h_n, c_n) = self.forecaster_rnn(x.float(), state)\n",
    "        else:\n",
    "            _, h_n = self.forecaster_rnn(x.float(), h_0)\n",
    "            c_n = None\n",
    "\n",
    "        out = self.forecaster_out(h_n).reshape(-1, self.horizon, self.output_size)\n",
    "\n",
    "        return out, (h_n, c_n)\n",
    "\n",
    "    def fit(self, train_dataset, batch_size, epochs, lr):\n",
    "        \"\"\"\n",
    "        Trains the auxiliary forecaster to the training dataset.\n",
    "        Args:\n",
    "            train_dataset: a dataset of type `torch.utils.data.Dataset`\n",
    "            batch_size: batch size\n",
    "            epochs: number of training epochs\n",
    "            lr: learning rate\n",
    "        \"\"\"\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = 0.0\n",
    "\n",
    "            for sequences, targets, lengths in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                out, _ = self(sequences)\n",
    "                valid_out = out * get_lengths_mask(sequences, lengths, self.horizon)\n",
    "\n",
    "                loss = criterion(valid_out.float(), targets.float())\n",
    "                loss.backward()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "            mean_train_loss = train_loss / len(train_loader)\n",
    "            if epoch % 50 == 0:\n",
    "                print(\"Epoch: {}\\tTrain loss: {}\".format(epoch, mean_train_loss))\n",
    "\n",
    "        if self.path is not None:\n",
    "            torch.save(self, self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f72c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HORIZON = 5\n",
    "ALPHA = .05\n",
    "def conformal_rnn(model,calibration,test,H=NUM_HORIZON,alpha=ALPHA):\n",
    "    X_t = calibration[:,:T] # torch tensor of size (m,T)\n",
    "    Y_h = calibration[:,T:] # torch tensor of size (m, H)\n",
    "    calibration_scores = [[] for i in range(H)]\n",
    "    M = len(X_t.shape[0])\n",
    "    new_epsilons = []\n",
    "    for m in range():\n",
    "        temp_output, _ = model(X_t[i,:]) #tensor of H values\n",
    "        for h in range(H):\n",
    "            epsilons.append([np.abs(temp_output[h] - Y_h[h])])\n",
    "    \n",
    "    for h in range(H):\n",
    "        cut_point = np.ceil((M + 1)(1-alpha/H))/M\n",
    "        new_epsilons.append(np.quantile(calibration_scores,cut_point))\n",
    "    \n",
    "\n",
    "    return new_epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25637ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 20\n",
    "learning_rate =0.01\n",
    "batch_size = 100\n",
    "epochs = 1000\n",
    "LSTM = AuxiliaryForecaster(emdedding_size, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeec215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c8448",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adaptive ConformalRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac46a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
